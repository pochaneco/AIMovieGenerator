/**
 * LLMã‚µãƒ¼ãƒ“ã‚¹ - å„ç¤¾ã®LLM APIã‚’çµ±ä¸€çš„ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ã‚µãƒ¼ãƒ“ã‚¹
 * LangChainã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¯¾å¿œ
 * è¤‡æ•°è¨­å®šã®ä¿å­˜ãƒ»ç®¡ç†æ©Ÿèƒ½ä»˜ã
 */

import { ChatOpenAI } from "@langchain/openai";
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import {
  HumanMessage,
  AIMessage,
  SystemMessage,
} from "@langchain/core/messages";
import {
  getLLMConfigs,
  getActiveLLMConfig,
  getSetting,
  saveSetting,
} from "../services/dataService.js";

// å¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å®šç¾©
export const LLM_PROVIDERS = {
  OPENAI: "openai",
  ANTHROPIC: "anthropic",
  GOOGLE: "google",
};

// ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æƒ…å ±
export const PROVIDER_INFO = {
  [LLM_PROVIDERS.OPENAI]: {
    name: "OpenAI",
    models: [
      "gpt-4.1",
      "o4-mini",
      "o3",
      "o3-pro (very expensive)",
      "o3-mini",
      "o1 (expensive)",
      "o1-mini",
      "o1-pro (most expensive)",
      "gpt-4",
      "gpt-3.5-turbo",
      "gpt-4o",
      "gpt-4o-nano",
    ],
    defaultModel: "gpt-4",
    apiKeyRequired: true,
    icon: "ğŸ¤–",
  },
  [LLM_PROVIDERS.ANTHROPIC]: {
    name: "Anthropic",
    models: [
      "claude-opus-4-20250514",
      "claude-sonnet-4-20250514",
      "claude-3-7-sonnet-20250219",
      "claude-3-5-haiku-20241022",
    ],
    defaultModel: "claude-3-sonnet-20240229",
    apiKeyRequired: true,
    icon: "ğŸ­",
  },
  [LLM_PROVIDERS.GOOGLE]: {
    name: "Google Gemini",
    models: [
      "gemini-2.5-pro",
      "gemini-2.5-flash",
      "gemini-2.0-flash",
      "gemini-1.5-flash",
    ],
    defaultModel: "gemini-pro",
    apiKeyRequired: true,
    icon: "ğŸ”",
  },
};

/**
 * è¨­å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
 */
export async function getLLMSettings() {
  try {
    const activeConfig = await getActiveLLMConfig();
    if (activeConfig) {
      return {
        provider: activeConfig.provider,
        model: activeConfig.defaultModel,
        config: activeConfig,
      };
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¤ã„è¨­å®šå½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯
    const provider = await getSetting("llm_provider", LLM_PROVIDERS.OPENAI);
    const model = await getSetting(
      "llm_model",
      PROVIDER_INFO[provider]?.defaultModel || "gpt-4"
    );
    return { provider, model, config: null };
  } catch (error) {
    console.error("LLMè¨­å®šã®å–å¾—ã«å¤±æ•—:", error);
    return {
      provider: LLM_PROVIDERS.OPENAI,
      model: PROVIDER_INFO[LLM_PROVIDERS.OPENAI].defaultModel,
      config: null,
    };
  }
}

/**
 * LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼ˆç‰¹å®šã®è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šï¼‰
 */
export async function createLLMInstance(configId = null, modelName = null) {
  let config, apiKey, model;

  if (configId) {
    // æŒ‡å®šã•ã‚ŒãŸè¨­å®šã‚’ä½¿ç”¨
    const configs = await getLLMConfigs();
    config = configs.find((c) => c.id === configId);
    if (!config) {
      throw new Error("æŒ‡å®šã•ã‚ŒãŸLLMè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
    }
    apiKey = config.apiKey;
    model = modelName || config.defaultModel;
  } else {
    // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¨­å®šã‚’ä½¿ç”¨
    const settings = await getLLMSettings();
    config = settings.config;
    if (!config) {
      throw new Error(
        "LLMè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨­å®šç”»é¢ã§LLMã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
      );
    }
    apiKey = config.apiKey;
    model = modelName || settings.model;
  }

  if (!apiKey) {
    throw new Error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚");
  }

  try {
    switch (config.provider) {
      case LLM_PROVIDERS.OPENAI:
        return new ChatOpenAI({
          openAIApiKey: apiKey,
          modelName: model,
          temperature: 0.7,
        });

      case LLM_PROVIDERS.ANTHROPIC:
        return new ChatAnthropic({
          anthropicApiKey: apiKey,
          modelName: model,
          temperature: 0.7,
        });

      case LLM_PROVIDERS.GOOGLE:
        return new ChatGoogleGenerativeAI({
          apiKey: apiKey,
          model: model, // modelNameã§ã¯ãªãmodel
          temperature: 0.7,
        });

      default:
        throw new Error(`ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${config.provider}`);
    }
  } catch (error) {
    console.error("LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆã«å¤±æ•—:", error);
    throw new Error(`LLMã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
  }
}

/**
 * ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆè¨­å®šIDã¨ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šå¯èƒ½ï¼‰
 */
export async function generateText(prompt, options = {}) {
  try {
    const { configId = null, modelName = null } = options;
    const llm = await createLLMInstance(configId, modelName);
    const response = await llm.invoke(prompt);
    return response.content;
  } catch (error) {
    console.error("ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error);
    throw error;
  }
}

/**
 * ã‚·ãƒ¼ãƒ³ä½œæˆé–¢æ•° - LLMãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨
 */
function createScene(title, description, duration = "2åˆ†") {
  return {
    id: Date.now() + Math.random(),
    type: "scene",
    title,
    content: description,
    duration,
    lines: [],
  };
}

/**
 * ã‚·ãƒ¼ãƒ³ã«ãƒ©ã‚¤ãƒ³è¿½åŠ é–¢æ•° - LLMãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨
 */
function addLineToScene(
  scene,
  character,
  content,
  emotion = "æ™®é€š",
  type = "line"
) {
  const line = {
    id: Date.now() + Math.random(),
    type,
    character,
    content,
    emotion,
  };

  if (!scene.lines) {
    scene.lines = [];
  }
  scene.lines.push(line);
  return line;
}

/**
 * å°æœ¬ç”Ÿæˆç”¨ã®å°‚ç”¨é–¢æ•°ï¼ˆè¨­å®šIDã¨ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šå¯èƒ½ï¼‰
 */
export async function generateScript(projectData, scriptData, options = {}) {
  const { configId = null, modelName = null, scriptSettings = {} } = options;

  // å°æœ¬è¨­å®šã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
  const settings = {
    totalDuration: scriptSettings.totalDuration || "10åˆ†",
    sceneCount: scriptSettings.sceneCount || 3,
    averageSceneDuration: scriptSettings.averageSceneDuration || "3åˆ†",
    ...scriptSettings,
  };

  const characters = projectData?.characters || [];
  const charactersInfo =
    characters.length > 0
      ? `ç™»å ´ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: ${characters
          .map((c) => `${c.name}(${c.role || c.description || ""})`)
          .join(", ")}`
      : "";

  // æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
  const prompt = `
ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€æ˜ ç”»ã®å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: ${projectData?.name || "æœªè¨­å®š"}
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜: ${projectData?.description || ""}
å°æœ¬ã‚¿ã‚¤ãƒˆãƒ«: ${scriptData?.title || "æœªè¨­å®š"}
å°æœ¬èª¬æ˜: ${scriptData?.description || ""}
${charactersInfo}

å°æœ¬è¨­å®š:
- å…¨ä½“ã®é•·ã•: ${settings.totalDuration}
- ã‚·ãƒ¼ãƒ³æ•°: ${settings.sceneCount}å€‹
- 1ã‚·ãƒ¼ãƒ³ã‚ãŸã‚Šã®å¹³å‡æ™‚é–“: ${settings.averageSceneDuration}

ä»¥ä¸‹ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å°æœ¬ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

## ã‚·ãƒ¼ãƒ³1: [ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒˆãƒ«] ([æ™‚é–“])
*[ã‚·ãƒ¼ãƒ³ã®èª¬æ˜ãƒ»çŠ¶æ³è¨­å®š]

ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å: ã‚»ãƒªãƒ•å†…å®¹ [æ„Ÿæƒ…]
ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å: ã‚»ãƒªãƒ•å†…å®¹ [æ„Ÿæƒ…]
ã€ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å†…å®¹ã€‘

## ã‚·ãƒ¼ãƒ³2: [ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒˆãƒ«] ([æ™‚é–“])
*[ã‚·ãƒ¼ãƒ³ã®èª¬æ˜ãƒ»çŠ¶æ³è¨­å®š]

...

è¦æ±‚:
1. å„ã‚·ãƒ¼ãƒ³ã«ã¯æ˜ç¢ºãªã‚¿ã‚¤ãƒˆãƒ«ã¨æ™‚é–“ã‚’è¨­å®š
2. ã‚·ãƒ¼ãƒ³ã®èª¬æ˜ã¯ã€Œ*ã€ã§å§‹ã‚ã‚‹
3. ã‚»ãƒªãƒ•ã¯ã€Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å: å†…å®¹ [æ„Ÿæƒ…]ã€ã®å½¢å¼
4. ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€Œã€ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: å†…å®¹ã€‘ã€ã®å½¢å¼
5. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å€‹æ€§ã‚’æ´»ã‹ã—ãŸè‡ªç„¶ãªå¯¾è©±
6. ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®èµ·æ‰¿è»¢çµã‚’æ„è­˜ã—ãŸæ§‹æˆ
7. å„ã‚·ãƒ¼ãƒ³ã®æ™‚é–“é…åˆ†ã¯è¨­å®šã«å¾“ã†

å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
`;

  try {
    console.log("å°æœ¬ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€ä¿¡:", {
      projectName: projectData?.name,
      scriptTitle: scriptData?.title,
      settings,
    });

    const llm = await createLLMInstance(configId, modelName);
    const response = await llm.invoke(prompt);

    console.log("å°æœ¬ç”Ÿæˆå®Œäº†");
    return response.content;
  } catch (error) {
    console.error("å°æœ¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error);
    throw new Error(`å°æœ¬ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`);
  }
}

/**
 * APIã‚­ãƒ¼ã®ãƒ†ã‚¹ãƒˆï¼ˆæ–°ã—ã„è¨­å®šå½¢å¼å¯¾å¿œï¼‰
 */
export async function testApiKey(provider, apiKey, model) {
  try {
    // å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼
    if (!provider || !apiKey || !model) {
      throw new Error(
        `å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: provider=${provider}, apiKey=${
          apiKey ? "****" : "ãªã—"
        }, model=${model}`
      );
    }

    console.log(`APIã‚­ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹: ${provider} / ${model}`);

    let llm;

    switch (provider) {
      case LLM_PROVIDERS.OPENAI:
        llm = new ChatOpenAI({
          openAIApiKey: apiKey,
          modelName: model,
          temperature: 0.1,
        });
        break;

      case LLM_PROVIDERS.ANTHROPIC:
        llm = new ChatAnthropic({
          anthropicApiKey: apiKey,
          modelName: model,
          temperature: 0.1,
        });
        break;

      case LLM_PROVIDERS.GOOGLE:
        console.log("Google Geminiè¨­å®š:", {
          apiKey: apiKey ? "****" : "ãªã—",
          model,
        });
        llm = new ChatGoogleGenerativeAI({
          apiKey: apiKey,
          model: model, // modelNameã§ã¯ãªãmodel
          temperature: 0.1,
        });
        break;

      default:
        throw new Error(`ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${provider}`);
    }

    // ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡å˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    const response = await llm.invoke(
      "Hello, please respond with 'API test successful'"
    );

    // responseã®æ§‹é€ ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦ãƒ‡ãƒãƒƒã‚°
    console.log("LLM Response for", provider, ":", response);

    // responseãŒundefinedã¾ãŸã¯nullã®å ´åˆã®å‡¦ç†
    if (!response) {
      throw new Error("LLMã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™");
    }

    // responseã®å†…å®¹ã‚’å–å¾—ï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚ˆã£ã¦æ§‹é€ ãŒç•°ãªã‚‹å¯èƒ½æ€§ï¼‰
    let content = response.content || response.text || response;

    // contentãŒæ–‡å­—åˆ—ã§ãªã„å ´åˆã®å‡¦ç†
    if (typeof content !== "string") {
      content = String(content);
    }

    return { success: true, response: content };
  } catch (error) {
    console.error("APIã‚­ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:", error);
    return { success: false, error: error.message };
  }
}

/**
 * è¨­å®šã‚’ãƒ†ã‚¹ãƒˆï¼ˆLLMè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ï¼‰
 */
export async function testLLMConfig(config) {
  return await testApiKey(config.provider, config.apiKey, config.defaultModel);
}

/**
 * åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä¸€è¦§ã‚’å–å¾—
 */
export function getAvailableProviders() {
  return Object.values(LLM_PROVIDERS).map((provider) => ({
    id: provider,
    ...PROVIDER_INFO[provider],
  }));
}

/**
 * ç‰¹å®šãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
 */
export function getAvailableModels(provider) {
  return PROVIDER_INFO[provider]?.models || [];
}

/**
 * è¨­å®šã®åå‰ã‚’ç”Ÿæˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
 */
export async function generateConfigName(provider) {
  const configs = await getLLMConfigs();
  const providerName = PROVIDER_INFO[provider]?.name || provider;
  const existing = configs.filter((c) => c.name.startsWith(providerName));

  if (existing.length === 0) {
    return providerName;
  }

  return `${providerName} (${existing.length + 1})`;
}

/**
 * ãƒãƒ£ãƒƒãƒˆç”¨ã®AIå¿œç­”ã‚’å–å¾—
 * @param {string|Array} messages - å˜ä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®é…åˆ—
 * @param {Object} config - LLMè¨­å®š
 */
export async function getChatResponse(messages, config = null) {
  try {
    // configãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–è¨­å®šã‚’ä½¿ç”¨
    const llmConfig = config || (await getActiveLLMConfig());

    if (!llmConfig) {
      throw new Error("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªLLMè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“");
    }

    let llm;
    const { provider, apiKey, defaultModel } = llmConfig;

    switch (provider) {
      case LLM_PROVIDERS.OPENAI:
        llm = new ChatOpenAI({
          openAIApiKey: apiKey,
          modelName: defaultModel,
          temperature: 0.7,
        });
        break;

      case LLM_PROVIDERS.ANTHROPIC:
        llm = new ChatAnthropic({
          anthropicApiKey: apiKey,
          modelName: defaultModel,
          temperature: 0.7,
        });
        break;

      case LLM_PROVIDERS.GOOGLE:
        llm = new ChatGoogleGenerativeAI({
          apiKey: apiKey,
          model: defaultModel,
          temperature: 0.7,
        });
        break;

      default:
        throw new Error(`ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${provider}`);
    }

    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é©åˆ‡ãªå½¢å¼ã«å¤‰æ›
    let input;
    if (typeof messages === "string") {
      // å˜ä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
      input = [new HumanMessage(messages)];
    } else if (Array.isArray(messages)) {
      // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®å ´åˆã€LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
      input = messages
        .filter((msg) => msg.role !== "system") // ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤å¤–
        .map((msg) => {
          if (msg.role === "user") {
            return new HumanMessage(msg.content);
          } else if (msg.role === "assistant") {
            return new AIMessage(msg.content);
          }
          return new HumanMessage(msg.content); // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯HumanMessage
        });

      // ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
      console.log(
        "é€ä¿¡ã•ã‚Œã‚‹ä¼šè©±å±¥æ­´:",
        input.map((msg) => ({
          type: msg.constructor.name,
          content: msg.content,
        }))
      );
    } else {
      input = [new HumanMessage(String(messages))];
    }

    // AIå¿œç­”ã‚’å–å¾—
    const response = await llm.invoke(input);

    // responseã®å†…å®¹ã‚’å–å¾—ï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«ã‚ˆã£ã¦æ§‹é€ ãŒç•°ãªã‚‹å¯èƒ½æ€§ï¼‰
    let content = response.content || response.text || response;

    // contentãŒæ–‡å­—åˆ—ã§ãªã„å ´åˆã®å‡¦ç†
    if (typeof content !== "string") {
      content = String(content);
    }

    return content;
  } catch (error) {
    console.error("ãƒãƒ£ãƒƒãƒˆå¿œç­”ã‚¨ãƒ©ãƒ¼:", error);
    throw new Error(error.message || "AIå¿œç­”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ");
  }
}
